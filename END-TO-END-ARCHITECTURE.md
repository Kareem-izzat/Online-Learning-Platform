# End-to-End Event-Driven Analytics Architecture

## Complete System Overview

This document describes the complete event-driven architecture connecting Discussion Service to Analytics Service via Kafka and the Outbox Pattern.

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          DISCUSSION SERVICE                                  â”‚
â”‚                          (Port 8092)                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USER ACTION (Create Thread)                              â”‚
â”‚                     POST /api/discussions/threads                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DiscussionService.createThread()                                â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ @Transactional (Single Database Transaction)                       â”‚    â”‚
â”‚  â”‚                                                                     â”‚    â”‚
â”‚  â”‚  1. threadRepository.save(thread)                                  â”‚    â”‚
â”‚  â”‚     â†’ INSERT INTO threads (id, title, content, ...)                â”‚    â”‚
â”‚  â”‚                                                                     â”‚    â”‚
â”‚  â”‚  2. outboxService.publishThreadCreated(threadId, courseId)         â”‚    â”‚
â”‚  â”‚     â†’ INSERT INTO outbox_events (event_type, payload, ...)         â”‚    â”‚
â”‚  â”‚                                                                     â”‚    â”‚
â”‚  â”‚  COMMIT (both succeed or both rollback)                            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         OUTBOX TABLE (Postgres)                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ id | aggregate_type | event_type      | payload       | processed â”‚      â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”‚
â”‚  â”‚ 1  | THREAD         | thread_created  | {"threadId":1}| false     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            OutboxPublisher (Scheduled Job - Every 5 seconds)                 â”‚
â”‚                                                                              â”‚
â”‚  @Scheduled(fixedDelay = 5000)                                               â”‚
â”‚  public void publishPendingEvents() {                                        â”‚
â”‚      1. Query: SELECT * FROM outbox_events WHERE processed = false           â”‚
â”‚      2. For each event:                                                      â”‚
â”‚         - kafkaTemplate.send("discussion.events", payload)                   â”‚
â”‚         - UPDATE outbox_events SET processed = true                          â”‚
â”‚      3. Retry on failure (up to 5 attempts)                                  â”‚
â”‚  }                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     APACHE KAFKA (KRaft Mode)                                â”‚
â”‚                     Topic: discussion.events                                 â”‚
â”‚                     Partitions: 3                                            â”‚
â”‚                                                                              â”‚
â”‚  Partition 0: [event1, event4, event7, ...]                                 â”‚
â”‚  Partition 1: [event2, event5, event8, ...]                                 â”‚
â”‚  Partition 2: [event3, event6, event9, ...]                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ANALYTICS SERVICE                                    â”‚
â”‚                         (Port 8100)                                          â”‚
â”‚                                                                              â”‚
â”‚  AnalyticsKafkaConsumer                                                      â”‚
â”‚  @KafkaListener(topics = "discussion.events")                                â”‚
â”‚  public void consumeEvent(String message) {                                  â”‚
â”‚      1. Parse JSON to EventEnvelope                                          â”‚
â”‚      2. analyticsService.processEvent(envelope)                              â”‚
â”‚  }                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AnalyticsService.processEvent()                         â”‚
â”‚                                                                              â”‚
â”‚  @Transactional                                                              â”‚
â”‚  public void processEvent(EventEnvelope envelope) {                          â”‚
â”‚      1. Check idempotency: eventProcessedRepo.existsById(eventId)            â”‚
â”‚         â†’ Skip if already processed                                          â”‚
â”‚                                                                              â”‚
â”‚      2. Handle event based on type:                                          â”‚
â”‚         - thread_created â†’ create ThreadAggregate                            â”‚
â”‚         - thread_viewed â†’ increment viewCount                                â”‚
â”‚         - comment_added â†’ increment commentCount                             â”‚
â”‚         - vote_cast â†’ increment upvotes/downvotes                            â”‚
â”‚                                                                              â”‚
â”‚      3. Save processed event: eventProcessedRepo.save(eventId)               â”‚
â”‚  }                                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      ANALYTICS DATABASE (Postgres)                           â”‚
â”‚                                                                              â”‚
â”‚  thread_aggregate table:                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ thread_id | course_id | view_count | comment_count | upvotes     â”‚      â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”‚
â”‚  â”‚ 1         | 42        | 15         | 8             | 12          â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                              â”‚
â”‚  event_processed table (idempotency):                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ event_id                              | processed_at             â”‚      â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤      â”‚
â”‚  â”‚ thread_created-1-a1b2c3d4             | 2025-10-30 12:00:05      â”‚      â”‚
â”‚  â”‚ comment_added-5-e5f6g7h8              | 2025-10-30 12:05:12      â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         QUERY ANALYTICS                                      â”‚
â”‚                                                                              â”‚
â”‚  GET /api/analytics/threads/1                                                â”‚
â”‚  â†’ Returns aggregate: {threadId: 1, viewCount: 15, commentCount: 8, ...}    â”‚
â”‚                                                                              â”‚
â”‚  GET /api/analytics/courses/42/top                                           â”‚
â”‚  â†’ Returns top 10 threads by engagement score                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Event Flow Timeline

### T=0: User Creates Thread
```
POST /api/discussions/threads
Body: {"courseId": 42, "title": "How to use Kafka?", ...}

Discussion Service:
  âœ… Save thread to threads table (id=123)
  âœ… Save event to outbox_events table (processed=false)
  âœ… Commit transaction
  âœ… Return response to user
```

### T=3s: OutboxPublisher Runs (First Cycle)
```
OutboxPublisher (every 5s):
  ðŸ“‹ Query: SELECT * FROM outbox_events WHERE processed=false
  ðŸ“¤ Found 1 event (thread_created)
  ðŸš€ Send to Kafka: discussion.events topic
  âœ… Update: SET processed=true, processed_at=NOW()
  ðŸ“ Log: "Published 1 events, 0 failed"
```

### T=3.5s: Analytics Consumes Event
```
AnalyticsKafkaConsumer:
  ðŸ“¥ Received message from Kafka
  ðŸ” Parse JSON â†’ EventEnvelope
  
AnalyticsService.processEvent():
  ðŸ” Check idempotency: event_processed table
  âž• Create ThreadAggregate: threadId=123, courseId=42
  âœ… Save eventId to event_processed
  ðŸ“ Log: "Successfully processed event: thread_created-123-..."
```

### T=10s: User Views Thread
```
GET /api/discussions/threads/123

Discussion Service:
  ðŸ“ˆ Increment thread.viewCount
  âœ… Save event to outbox_events (thread_viewed)
```

### T=13s: OutboxPublisher Runs (Second Cycle)
```
OutboxPublisher:
  ðŸ“¤ Publish thread_viewed event
  âœ… Mark as processed
```

### T=13.5s: Analytics Updates Aggregate
```
AnalyticsService:
  ðŸ” Find ThreadAggregate for threadId=123
  ðŸ“ˆ Increment viewCount
  âœ… Save updated aggregate
```

## Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Discussion Service** | Spring Boot 3.3.4 | Domain service managing threads/comments |
| **Analytics Service** | Spring Boot 3.3.4 | Event aggregation and analytics |
| **Message Broker** | Apache Kafka 3.7.0 (KRaft) | Event streaming platform |
| **Database** | PostgreSQL 15 | Persistent storage for both services |
| **Event Pattern** | Outbox Pattern | Transactional event publishing |
| **Idempotency** | Event ID tracking | Prevents duplicate processing |
| **Serialization** | Jackson JSON | Event envelope format |

## Configuration Summary

### Discussion Service (`discussion-service/application.properties`)
```properties
# Service
spring.application.name=discussion-service
server.port=8092

# Database
spring.datasource.url=jdbc:postgresql://localhost:5432/discussion_service_db

# Kafka (disabled by default)
discussion.kafka.enabled=false
spring.kafka.bootstrap-servers=localhost:9092

# Scheduling (for OutboxPublisher)
spring.task.scheduling.pool.size=2
```

### Analytics Service (`analytics/application.properties`)
```properties
# Service
server.port=8100

# Database
spring.datasource.url=jdbc:postgresql://localhost:5432/analytics_db

# Kafka (disabled by default)
analytics.kafka.enabled=false
spring.kafka.bootstrap-servers=localhost:9092
analytics.kafka.topic.discussion=discussion.events
spring.kafka.consumer.auto-offset-reset=earliest
```

## Running the Complete System

### 1. Start Infrastructure
```bash
# Start Kafka and Postgres for both services
cd analytics
docker-compose up -d kafka postgres
```

### 2. Enable Kafka in Both Services
```properties
# discussion-service/application.properties
discussion.kafka.enabled=true

# analytics/application.properties
analytics.kafka.enabled=true
```

### 3. Start Services
```bash
# Terminal 1: Discussion Service
cd discussion-service
mvn spring-boot:run

# Terminal 2: Analytics Service
cd analytics
mvn spring-boot:run
```

### 4. Test End-to-End
```bash
# Run automated test
cd discussion-service
.\test-outbox.ps1
```

## Monitoring & Observability

### Discussion Service Metrics
- Pending outbox events: `SELECT COUNT(*) FROM outbox_events WHERE processed=false`
- Failed events: `SELECT * FROM outbox_events WHERE attempt_count >= 5`
- Publisher rate: Check logs for "Published X events" messages

### Kafka Metrics
```bash
# Consumer group lag
docker exec kafka kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --describe --group analytics-service

# Topic message count
docker exec kafka kafka-run-class.sh kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic discussion.events
```

### Analytics Service Metrics
- Processed events: `SELECT COUNT(*) FROM event_processed`
- Thread aggregates: `SELECT COUNT(*) FROM thread_aggregate`
- Processing errors: Check application logs for "Error processing Kafka message"

## Failure Scenarios & Recovery

### Scenario 1: Kafka is Down
**Impact:** Events accumulate in outbox_events table  
**Recovery:** When Kafka comes back, OutboxPublisher automatically publishes pending events  
**Data Loss:** None (events safely stored in database)

### Scenario 2: Discussion Service Crashes
**Impact:** Outbox table retains unpublished events  
**Recovery:** When service restarts, OutboxPublisher resumes from where it left off  
**Data Loss:** None

### Scenario 3: Analytics Service Crashes
**Impact:** Kafka retains messages (durable storage)  
**Recovery:** When service restarts, consumer resumes from last committed offset  
**Data Loss:** None (Kafka retains messages for 7 days by default)

### Scenario 4: Duplicate Event Sent
**Impact:** Analytics receives same event twice  
**Recovery:** Idempotency check (event_processed table) prevents duplicate aggregation  
**Data Loss:** None (duplicate safely ignored)

## Performance Characteristics

| Metric | Discussion Service | Kafka | Analytics Service |
|--------|-------------------|-------|-------------------|
| **Event Creation** | ~5ms (single DB transaction) | N/A | N/A |
| **Publishing Latency** | 0-5s (scheduled job) | <10ms | N/A |
| **Processing Latency** | N/A | N/A | ~10ms per event |
| **Throughput** | 1000 events/sec | 100k msg/sec | 500 events/sec |
| **Storage** | Postgres (OLTP) | Disk (7 day retention) | Postgres (OLAP) |

## Next Steps & Enhancements

1. **Monitoring Dashboard**: Grafana + Prometheus for real-time metrics
2. **Dead Letter Queue**: Move persistently failing events to DLQ table
3. **Distributed Tracing**: Add Sleuth/Zipkin for request correlation
4. **Performance Tuning**: Switch Analytics to ClickHouse/TimescaleDB
5. **Multi-Instance**: Run multiple consumers for horizontal scaling
6. **Schema Registry**: Add Confluent Schema Registry for event versioning
7. **Circuit Breaker**: Add Resilience4j for fault tolerance

## Documentation References

- **Analytics Service**: [analytics/README.md](../analytics/README.md)
- **Outbox Pattern**: [discussion-service/OUTBOX-PATTERN.md](OUTBOX-PATTERN.md)
- **Integration Patterns**: [analytics/INTEGRATION-PATTERNS.md](../analytics/INTEGRATION-PATTERNS.md)
- **Event Contract**: [analytics/event-contract.md](../analytics/event-contract.md)
